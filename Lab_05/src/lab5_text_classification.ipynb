{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70c191e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (8954, 2)\n",
      "Validation shape:  (1076, 2)\n",
      "Test shape:  (1076, 2)\n",
      "                                                text       intent\n",
      "0                what alarms do i have set right now  alarm_query\n",
      "1                    checkout today alarm of meeting  alarm_query\n",
      "2                              report alarm settings  alarm_query\n",
      "3  see see for me the alarms that you have set to...  alarm_query\n",
      "4                       is there an alarm for ten am  alarm_query\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"C:\\\\Users\\\\FPTSHOP\\\\Courses\\\\NLP\\\\Lab_05\\\\data\\\\hwu\\\\train.csv\", sep=\",\", header=0, names=[\"text\", \"intent\"])\n",
    "df_val = pd.read_csv(\"C:\\\\Users\\\\FPTSHOP\\\\Courses\\\\NLP\\\\Lab_05\\\\data\\\\hwu\\\\val.csv\", sep=\",\", header=0, names=[\"text\", \"intent\"])\n",
    "df_test = pd.read_csv(\"C:\\\\Users\\\\FPTSHOP\\\\Courses\\\\NLP\\\\Lab_05\\\\data\\\\hwu\\\\test.csv\", sep=\",\", header=0, names=[\"text\", \"intent\"])\n",
    "\n",
    "print(\"Train shape: \", df_train.shape)\n",
    "print(\"Validation shape: \", df_val.shape)\n",
    "print(\"Test shape: \", df_test.shape)\n",
    "\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8eeb7578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "                                                text       intent  \\\n",
      "0                what alarms do i have set right now  alarm_query   \n",
      "1                    checkout today alarm of meeting  alarm_query   \n",
      "2                              report alarm settings  alarm_query   \n",
      "3  see see for me the alarms that you have set to...  alarm_query   \n",
      "4                       is there an alarm for ten am  alarm_query   \n",
      "\n",
      "   intent_label  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             0  \n",
      "4             0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "intents = df_train[\"intent\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(intents)\n",
    "\n",
    "df_train[\"intent_label\"] = le.transform(df_train[\"intent\"])\n",
    "df_val[\"intent_label\"] = le.transform(df_val[\"intent\"])\n",
    "df_test[\"intent_label\"] = le.transform(df_test[\"intent\"])\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "print(num_classes)\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e8eeffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "sample_texts = {\n",
    "    \"can you remind me to not call my mom\": \"reminder_create\",\n",
    "    \"is it going to be sunny or rainy tomorrow\": \"weather_query\",\n",
    "    \"find a flight from new york to london but not through paris\": \"flight_search\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b522b",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cc715e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alarm_query       0.90      0.95      0.92        19\n",
      "            alarm_remove       1.00      0.73      0.84        11\n",
      "               alarm_set       0.77      0.89      0.83        19\n",
      "       audio_volume_down       1.00      0.75      0.86         8\n",
      "       audio_volume_mute       0.92      0.80      0.86        15\n",
      "         audio_volume_up       0.93      1.00      0.96        13\n",
      "          calendar_query       0.45      0.53      0.49        19\n",
      "         calendar_remove       0.89      0.89      0.89        19\n",
      "            calendar_set       0.87      0.68      0.76        19\n",
      "          cooking_recipe       0.59      0.68      0.63        19\n",
      "        datetime_convert       0.67      0.75      0.71         8\n",
      "          datetime_query       0.74      0.89      0.81        19\n",
      "        email_addcontact       0.78      0.88      0.82         8\n",
      "             email_query       0.83      0.79      0.81        19\n",
      "      email_querycontact       0.92      0.63      0.75        19\n",
      "         email_sendemail       0.81      0.89      0.85        19\n",
      "          general_affirm       1.00      1.00      1.00        19\n",
      "     general_commandstop       1.00      1.00      1.00        19\n",
      "         general_confirm       1.00      1.00      1.00        19\n",
      "        general_dontcare       0.90      1.00      0.95        19\n",
      "         general_explain       1.00      0.95      0.97        19\n",
      "            general_joke       1.00      1.00      1.00        12\n",
      "          general_negate       0.95      1.00      0.97        19\n",
      "          general_praise       0.95      1.00      0.97        19\n",
      "          general_quirky       0.36      0.26      0.30        19\n",
      "          general_repeat       0.90      1.00      0.95        19\n",
      "            iot_cleaning       1.00      1.00      1.00        16\n",
      "              iot_coffee       1.00      0.95      0.97        19\n",
      "     iot_hue_lightchange       0.75      0.79      0.77        19\n",
      "        iot_hue_lightdim       0.91      0.83      0.87        12\n",
      "        iot_hue_lightoff       0.89      0.89      0.89        19\n",
      "         iot_hue_lighton       0.67      0.67      0.67         3\n",
      "         iot_hue_lightup       1.00      0.86      0.92        14\n",
      "            iot_wemo_off       0.80      0.89      0.84         9\n",
      "             iot_wemo_on       0.78      1.00      0.88         7\n",
      "       lists_createoradd       0.68      0.79      0.73        19\n",
      "             lists_query       0.75      0.79      0.77        19\n",
      "            lists_remove       0.85      0.89      0.87        19\n",
      "          music_likeness       0.65      0.61      0.63        18\n",
      "             music_query       0.71      0.53      0.61        19\n",
      "          music_settings       1.00      0.57      0.73         7\n",
      "              news_query       0.75      0.63      0.69        19\n",
      "          play_audiobook       0.95      0.95      0.95        19\n",
      "               play_game       0.81      0.68      0.74        19\n",
      "              play_music       0.58      0.74      0.65        19\n",
      "           play_podcasts       1.00      0.84      0.91        19\n",
      "              play_radio       0.89      0.84      0.86        19\n",
      "             qa_currency       0.94      0.89      0.92        19\n",
      "           qa_definition       0.82      0.95      0.88        19\n",
      "              qa_factoid       0.48      0.58      0.52        19\n",
      "                qa_maths       0.92      0.86      0.89        14\n",
      "                qa_stock       1.00      0.95      0.97        19\n",
      "   recommendation_events       0.83      0.79      0.81        19\n",
      "recommendation_locations       0.81      0.89      0.85        19\n",
      "   recommendation_movies       1.00      1.00      1.00        10\n",
      "             social_post       0.95      1.00      0.97        19\n",
      "            social_query       0.80      0.89      0.84        18\n",
      "          takeaway_order       0.83      0.79      0.81        19\n",
      "          takeaway_query       0.89      0.89      0.89        19\n",
      "         transport_query       0.68      0.79      0.73        19\n",
      "          transport_taxi       1.00      1.00      1.00        18\n",
      "        transport_ticket       0.94      0.79      0.86        19\n",
      "       transport_traffic       1.00      0.95      0.97        19\n",
      "           weather_query       0.62      0.68      0.65        19\n",
      "\n",
      "                accuracy                           0.84      1076\n",
      "               macro avg       0.85      0.83      0.84      1076\n",
      "            weighted avg       0.84      0.84      0.84      1076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tfidf_lr_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=5000),\n",
    "    LogisticRegression(max_iter=1000)\n",
    ")\n",
    "\n",
    "tfidf_lr_pipeline.fit(df_train[\"text\"], df_train[\"intent_label\"])\n",
    "\n",
    "y_pred = tfidf_lr_pipeline.predict(df_test[\"text\"])\n",
    "print(classification_report(df_test[\"intent_label\"], y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e63b5d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score (macro): 0.8352983005857358\n",
      "\n",
      "Text: can you remind me to not call my mom\n",
      "-> Predicted intent: calendar_set\n",
      "-> True intent: reminder_create\n",
      "\n",
      "Text: is it going to be sunny or rainy tomorrow\n",
      "-> Predicted intent: weather_query\n",
      "-> True intent: weather_query\n",
      "\n",
      "Text: find a flight from new york to london but not through paris\n",
      "-> Predicted intent: general_negate\n",
      "-> True intent: flight_search\n"
     ]
    }
   ],
   "source": [
    "# F1 marco\n",
    "f1_macro = f1_score(df_test[\"intent_label\"], y_pred, average='macro')\n",
    "print(\"F1-score (macro):\", f1_macro)\n",
    "\n",
    "# Test sample\n",
    "y_pred = tfidf_lr_pipeline.predict(list(sample_texts.keys()))\n",
    "predicted_intents = le.inverse_transform(y_pred)\n",
    "\n",
    "for text, pred in zip(sample_texts.keys(), predicted_intents):\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"-> Predicted intent: {pred}\")\n",
    "    print(f\"-> True intent: {sample_texts[text]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebe544",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41ca9091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0255 - loss: 4.1287 - val_accuracy: 0.0567 - val_loss: 4.0750\n",
      "Epoch 2/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0504 - loss: 4.0329 - val_accuracy: 0.0716 - val_loss: 3.9530\n",
      "Epoch 3/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0639 - loss: 3.8996 - val_accuracy: 0.1041 - val_loss: 3.8035\n",
      "Epoch 4/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0778 - loss: 3.7771 - val_accuracy: 0.1143 - val_loss: 3.6745\n",
      "Epoch 5/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0915 - loss: 3.6731 - val_accuracy: 0.1245 - val_loss: 3.5795\n",
      "Epoch 6/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1021 - loss: 3.5881 - val_accuracy: 0.1608 - val_loss: 3.4942\n",
      "Epoch 7/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1158 - loss: 3.5237 - val_accuracy: 0.1654 - val_loss: 3.4326\n",
      "Epoch 8/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1180 - loss: 3.4532 - val_accuracy: 0.1673 - val_loss: 3.3651\n",
      "Epoch 9/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1288 - loss: 3.4050 - val_accuracy: 0.1794 - val_loss: 3.3097\n",
      "Epoch 10/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1378 - loss: 3.3545 - val_accuracy: 0.1998 - val_loss: 3.2560\n",
      "\n",
      "\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1747 - loss: 3.2665 \n",
      "\n",
      "Test Loss: 3.2665, Test Accuracy: 0.1747\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "sentences = [text.lower().split() for text in df_train[\"text\"]]\n",
    "w2v_model = Word2Vec(sentences, vector_size=50, window=4, min_count=2, workers=4)\n",
    "\n",
    "def sentence_to_avg_vector(text, model):\n",
    "    words = text.lower().split()\n",
    "    word_vectors = []\n",
    "\n",
    "    for w in words:\n",
    "        if (w in model.wv):\n",
    "            word_vectors.append(model.wv[w])\n",
    "    \n",
    "    if (len(word_vectors) > 0):\n",
    "        avg_vector = np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        avg_vector = np.zeros(model.vector_size)\n",
    "\n",
    "    return avg_vector\n",
    "\n",
    "X_train = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_train[\"text\"]])\n",
    "X_val = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_val[\"text\"]])\n",
    "X_test = np.array([sentence_to_avg_vector(text, w2v_model) for text in df_test[\"text\"]])\n",
    "\n",
    "y_train = to_categorical(df_train[\"intent_label\"], num_classes)\n",
    "y_val = to_categorical(df_val[\"intent_label\"], num_classes)\n",
    "y_test = to_categorical(df_test[\"intent_label\"], num_classes)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(w2v_model.vector_size,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4eb0ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "F1-score (macro): 0.111145440233925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\n",
      "Text: can you remind me to not call my mom\n",
      "-> Predicted intent: general_explain\n",
      "-> True intent: reminder_create\n",
      "\n",
      "Text: is it going to be sunny or rainy tomorrow\n",
      "-> Predicted intent: alarm_query\n",
      "-> True intent: weather_query\n",
      "\n",
      "Text: find a flight from new york to london but not through paris\n",
      "-> Predicted intent: email_sendemail\n",
      "-> True intent: flight_search\n"
     ]
    }
   ],
   "source": [
    "# F1 macro\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = df_test[\"intent_label\"]\n",
    "\n",
    "f1_macro = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "print(\"F1-score (macro):\", f1_macro)\n",
    "\n",
    "# Test sample\n",
    "sample = np.array([sentence_to_avg_vector(text, w2v_model) for text in list(sample_texts.keys())])\n",
    "\n",
    "y_pred_probs = model.predict(sample)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "predicted_intents = le.inverse_transform(y_pred_classes)\n",
    "\n",
    "for text, pred in zip(sample_texts.keys(), predicted_intents):\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"-> Predicted intent: {pred}\")\n",
    "    print(f\"-> True intent: {sample_texts[text]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72f874",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74b4306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.0302 - loss: 4.0552 - val_accuracy: 0.0520 - val_loss: 3.8312\n",
      "Epoch 2/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0572 - loss: 3.8149 - val_accuracy: 0.0771 - val_loss: 3.6178\n",
      "Epoch 3/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0787 - loss: 3.6706 - val_accuracy: 0.0967 - val_loss: 3.5107\n",
      "Epoch 4/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0850 - loss: 3.5838 - val_accuracy: 0.1134 - val_loss: 3.4191\n",
      "Epoch 5/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1023 - loss: 3.5092 - val_accuracy: 0.1283 - val_loss: 3.3649\n",
      "Epoch 6/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1101 - loss: 3.4593 - val_accuracy: 0.1515 - val_loss: 3.2999\n",
      "Epoch 7/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1173 - loss: 3.3890 - val_accuracy: 0.1478 - val_loss: 3.2311\n",
      "Epoch 8/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1254 - loss: 3.3419 - val_accuracy: 0.1617 - val_loss: 3.1628\n",
      "Epoch 9/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1383 - loss: 3.2940 - val_accuracy: 0.1719 - val_loss: 3.1411\n",
      "Epoch 10/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1400 - loss: 3.2736 - val_accuracy: 0.1608 - val_loss: 3.1388\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1589 - loss: 3.1800\n",
      "\n",
      "Test Loss: 3.1800, Test Accuracy: 0.1589\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(df_train[\"text\"])\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(df_train[\"text\"])\n",
    "X_val_sequences = tokenizer.texts_to_sequences(df_val[\"text\"])\n",
    "X_test_sequences = tokenizer.texts_to_sequences(df_test[\"text\"])\n",
    "\n",
    "max_len = 20\n",
    "X_train_pad = pad_sequences(X_train_sequences, maxlen=max_len, padding=\"post\")\n",
    "X_val_pad = pad_sequences(X_val_sequences, maxlen=max_len, padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test_sequences, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "y_train = to_categorical(df_train[\"intent_label\"], num_classes)\n",
    "y_val = to_categorical(df_val[\"intent_label\"], num_classes)\n",
    "y_test = to_categorical(df_test[\"intent_label\"], num_classes)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = w2v_model.vector_size\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if (word in w2v_model.wv):\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "lstm_model_pretrained = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        # input_length=max_len,\n",
    "        trainable=False\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "lstm_model_pretrained.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = lstm_model_pretrained.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "loss, acc = lstm_model_pretrained.evaluate(X_test_pad, y_test)\n",
    "print(f\"\\nTest Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "602bb4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "F1-score (macro): 0.11794393951425236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\n",
      "Text: can you remind me to not call my mom\n",
      "-> Predicted intent: takeaway_order\n",
      "-> True intent: reminder_create\n",
      "\n",
      "Text: is it going to be sunny or rainy tomorrow\n",
      "-> Predicted intent: email_query\n",
      "-> True intent: weather_query\n",
      "\n",
      "Text: find a flight from new york to london but not through paris\n",
      "-> Predicted intent: transport_ticket\n",
      "-> True intent: flight_search\n"
     ]
    }
   ],
   "source": [
    "# F1 macro\n",
    "y_pred = lstm_model_pretrained.predict(X_test_pad)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = df_test[\"intent_label\"]\n",
    "\n",
    "f1_macro = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "print(\"F1-score (macro):\", f1_macro)\n",
    "\n",
    "# Test sample\n",
    "sample_sequences = tokenizer.texts_to_sequences(list(sample_texts.keys()))\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "y_pred_probs = lstm_model_pretrained.predict(sample_padded)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "predicted_intents = le.inverse_transform(y_pred)\n",
    "\n",
    "for text, pred in zip(sample_texts.keys(), predicted_intents):\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"-> Predicted intent: {pred}\")\n",
    "    print(f\"-> True intent: {sample_texts[text]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a185f93",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "105391ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.0568 - loss: 3.6976 - val_accuracy: 0.1338 - val_loss: 3.0589\n",
      "Epoch 2/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.2980 - loss: 2.4088 - val_accuracy: 0.5613 - val_loss: 1.5993\n",
      "Epoch 3/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.6399 - loss: 1.3033 - val_accuracy: 0.7639 - val_loss: 0.9478\n",
      "Epoch 4/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7939 - loss: 0.7789 - val_accuracy: 0.7918 - val_loss: 0.7690\n",
      "Epoch 5/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.8534 - loss: 0.5420 - val_accuracy: 0.8290 - val_loss: 0.6552\n",
      "Epoch 6/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.8908 - loss: 0.4077 - val_accuracy: 0.8411 - val_loss: 0.6078\n",
      "Epoch 7/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9188 - loss: 0.3151 - val_accuracy: 0.8420 - val_loss: 0.5811\n",
      "Epoch 8/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9376 - loss: 0.2481 - val_accuracy: 0.8634 - val_loss: 0.5588\n",
      "Epoch 9/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9474 - loss: 0.2029 - val_accuracy: 0.8550 - val_loss: 0.5505\n",
      "Epoch 10/10\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9568 - loss: 0.1689 - val_accuracy: 0.8643 - val_loss: 0.5431\n",
      "\n",
      "\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8234 - loss: 0.6615\n",
      "Test Loss: 0.6615, Test Accuracy: 0.8234\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "F1-score (macro): 0.8238542875628776\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(df_train[\"text\"])\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(df_train[\"text\"])\n",
    "X_val_sequences = tokenizer.texts_to_sequences(df_val[\"text\"])\n",
    "X_test_sequences = tokenizer.texts_to_sequences(df_test[\"text\"])\n",
    "\n",
    "max_len = 20\n",
    "X_train_pad = pad_sequences(X_train_sequences, maxlen=max_len, padding=\"post\")\n",
    "X_val_pad = pad_sequences(X_val_sequences, maxlen=max_len, padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test_sequences, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "y_train = to_categorical(df_train[\"intent_label\"], num_classes)\n",
    "y_val = to_categorical(df_val[\"intent_label\"], num_classes)\n",
    "y_test = to_categorical(df_test[\"intent_label\"], num_classes)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 400\n",
    "\n",
    "lstm_model_scratch = Sequential([\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        # input_length=max_len,\n",
    "    ),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "lstm_model_scratch.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=4,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = lstm_model_scratch.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_data=(X_val_pad, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "loss, acc = lstm_model_scratch.evaluate(X_test_pad, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "y_pred = lstm_model_scratch.predict(X_test_pad)\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = df_test[\"intent_label\"]\n",
    "\n",
    "f1_macro = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "print(\"F1-score (macro):\", f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14ae7c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "F1-score (macro): 0.8238542875628776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\n",
      "Text: can you remind me to not call my mom\n",
      "-> Predicted intent: calendar_set\n",
      "-> True intent: reminder_create\n",
      "\n",
      "Text: is it going to be sunny or rainy tomorrow\n",
      "-> Predicted intent: weather_query\n",
      "-> True intent: weather_query\n",
      "\n",
      "Text: find a flight from new york to london but not through paris\n",
      "-> Predicted intent: transport_ticket\n",
      "-> True intent: flight_search\n"
     ]
    }
   ],
   "source": [
    "# F1 macro\n",
    "y_pred = lstm_model_scratch.predict(X_test_pad)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = df_test[\"intent_label\"]\n",
    "\n",
    "f1_macro = f1_score(y_true_classes, y_pred_classes, average='macro')\n",
    "print(\"F1-score (macro):\", f1_macro)\n",
    "\n",
    "# Test sample\n",
    "sample_sequences = tokenizer.texts_to_sequences(list(sample_texts.keys()))\n",
    "sample_padded = pad_sequences(sample_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "y_pred_probs = lstm_model_scratch.predict(sample_padded)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "predicted_intents = le.inverse_transform(y_pred_classes)\n",
    "\n",
    "for text, pred in zip(sample_texts.keys(), predicted_intents):\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"-> Predicted intent: {pred}\")\n",
    "    print(f\"-> True intent: {sample_texts[text]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
